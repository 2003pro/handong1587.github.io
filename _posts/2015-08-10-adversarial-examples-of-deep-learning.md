---
layout: post
title: Adversarial Examples of Deep Learning
---

{{ page.title }}
================

<p class="meta">10 Apr 2015 - Beijing</p>

**Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images**:

- paper: [arXiv:1412.1897](http://arxiv.org/abs/1412.1897)

**Explaining and Harnessing Adversarial Examples**:

- paper: [arXiv:1412.6572](http://arxiv.org/abs/1412.6572)

**Intriguing properties of neural networks**:

- paper: [arXiv:1312.6199](http://arxiv.org/abs/1312.6199)

**Distributional Smoothing with Virtual Adversarial Training**:

- paper: [arXiv:1507.00677](http://arxiv.org/abs/1507.00677)
- code: [vat](https://github.com/takerum/vat)

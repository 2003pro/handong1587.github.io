---
layout: post
categories: deep_learning
title: Adversarial Examples of Deep Learning
---

{{ page.title }}
================

<p class="meta">10 Aug 2015 - Beijing</p>

**Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images**:

- paper: [http://arxiv.org/abs/1412.1897](http://arxiv.org/abs/1412.1897)
- code: [https://github.com/Evolving-AI-Lab/fooling/](https://github.com/Evolving-AI-Lab/fooling/)

**Explaining and Harnessing Adversarial Examples**:

- paper: [http://arxiv.org/abs/1412.6572](http://arxiv.org/abs/1412.6572)

**Intriguing properties of neural networks**:

- paper: [http://arxiv.org/abs/1312.6199](http://arxiv.org/abs/1312.6199)

**Distributional Smoothing with Virtual Adversarial Training**:

- paper: [http://arxiv.org/abs/1507.00677](http://arxiv.org/abs/1507.00677)
- code: [https://github.com/takerum/vat](https://github.com/takerum/vat)

**Confusing Deep Convolution Networks by Relabelling**

- arXiv: [http://arxiv.org/abs/1510.06925v1](http://arxiv.org/abs/1510.06925v1)

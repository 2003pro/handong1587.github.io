---
layout: post
categories: deep_learning
title: Language Computation
---

{{ page.title }}
================

<p class="meta">11 Sep 2015 - Beijing</p>

**Neural Machine Translation by Jointly Learning to Align and Translate**

- arXiv: [http://arxiv.org/abs/1409.0473](http://arxiv.org/abs/1409.0473)
- github: [https://github.com/lisa-groundhog/GroundHog](https://github.com/lisa-groundhog/GroundHog)

**Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models**

<img src="/assets/dl-materials/Unifying_Visual-Semantic_Embeddings_with_Multimodal_Neural_Language_Models.png" width="600" />

- paper: [http://arxiv.org/abs/1411.2539](http://arxiv.org/abs/1411.2539)
- results: [http://www.cs.toronto.edu/~rkiros/lstm_scnlm.html](http://www.cs.toronto.edu/~rkiros/lstm_scnlm.html)
- demo: [http://deeplearning.cs.toronto.edu/i2t](http://deeplearning.cs.toronto.edu/i2t)
- github: [https://github.com/ryankiros/visual-semantic-embedding](https://github.com/ryankiros/visual-semantic-embedding)

**Show and Tell: A Neural Image Caption Generator(Google)**

- arXiv: [http://arxiv.org/abs/1411.4555](http://arxiv.org/abs/1411.4555)
- github: [https://github.com/karpathy/neuraltalk](https://github.com/karpathy/neuraltalk)
- GitXiv: [http://gitxiv.com/posts/7nofxjoYBXga5XjtL/show-and-tell-a-neural-image-caption-nic-generator](http://gitxiv.com/posts/7nofxjoYBXga5XjtL/show-and-tell-a-neural-image-caption-nic-generator)

**Show, Attend and Tell: Neural Image Caption Generation with Visual Attention**

- arXiv: [http://arxiv.org/abs/1502.03044](http://arxiv.org/abs/1502.03044)
- github: [https://github.com/kelvinxu/arctic-captions](https://github.com/kelvinxu/arctic-captions)

**Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks(Facebook AI Research)**

- arXiv: [http://arxiv.org/abs/1502.05698v1](http://arxiv.org/abs/1502.05698v1)
- github: [https://github.com/facebook/bAbI-tasks](https://github.com/facebook/bAbI-tasks)

**Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks**

- arXiv: [http://arxiv.org/abs/1503.00075](http://arxiv.org/abs/1503.00075)
- github: [https://github.com/stanfordnlp/treelstm](https://github.com/stanfordnlp/treelstm)

**Teaching Machines to Read and Comprehend(Google DeepMind)**

- arXiv: [http://arxiv.org/abs/1506.03340](http://arxiv.org/abs/1506.03340)
- github: [https://github.com/deepmind/rc-data](https://github.com/deepmind/rc-data)

**Skip-Thought Vectors**

- arXiv: [http://arxiv.org/abs/1506.06726](http://arxiv.org/abs/1506.06726)
- github: [https://github.com/ryankiros/skip-thoughts](https://github.com/ryankiros/skip-thoughts)

**Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books**

- arXiv: [http://arxiv.org/abs/1506.06724](http://arxiv.org/abs/1506.06724)
- github: [https://github.com/ryankiros/neural-storyteller](https://github.com/ryankiros/neural-storyteller)

**A Neural Attention Model for Abstractive Sentence Summarization(EMNLP 2015. Facebook AI Research)**

- arXiv: [http://arxiv.org/abs/1509.00685](http://arxiv.org/abs/1509.00685)
- github: [https://github.com/facebook/NAMAS](https://github.com/facebook/NAMAS)

**Generating Text with Deep Reinforcement Learning(NIPS 2015)**

- arXiv: [http://arxiv.org/abs/1510.09202](http://arxiv.org/abs/1510.09202)

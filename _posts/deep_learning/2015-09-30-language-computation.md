---
layout: post
categories: deep_learning
title: Language Computation Materials
---

{{ page.title }}
================

<p class="meta">11 Sep 2015 - Beijing</p>

**Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models**

<img src="/assets/dl-materials/Unifying_Visual-Semantic_Embeddings_with_Multimodal_Neural_Language_Models.png" width="600" />

- paper: [http://arxiv.org/abs/1411.2539](http://arxiv.org/abs/1411.2539)
- results: [http://www.cs.toronto.edu/~rkiros/lstm_scnlm.html](http://www.cs.toronto.edu/~rkiros/lstm_scnlm.html)
- demo: [http://deeplearning.cs.toronto.edu/i2t](http://deeplearning.cs.toronto.edu/i2t)
- github: [https://github.com/ryankiros/visual-semantic-embedding](https://github.com/ryankiros/visual-semantic-embedding)

**Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks(Facebook AI Research)**

- arXiv: [http://arxiv.org/abs/1502.05698v1](http://arxiv.org/abs/1502.05698v1)
- github: [https://github.com/facebook/bAbI-tasks](https://github.com/facebook/bAbI-tasks)

**Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks**

- arXiv: [http://arxiv.org/abs/1503.00075](http://arxiv.org/abs/1503.00075)
- github: [https://github.com/stanfordnlp/treelstm](https://github.com/stanfordnlp/treelstm)

**Teaching Machines to Read and Comprehend(Google DeepMind)**

- arXiv: [http://arxiv.org/abs/1506.03340](http://arxiv.org/abs/1506.03340)
- github: [https://github.com/deepmind/rc-data](https://github.com/deepmind/rc-data)

**A Neural Attention Model for Abstractive Sentence Summarization(EMNLP 2015. Facebook AI Research)**

- arXiv: [http://arxiv.org/abs/1509.00685](http://arxiv.org/abs/1509.00685)
- github: [https://github.com/facebook/NAMAS](https://github.com/facebook/NAMAS)

---
layout: post
category: deep_learning
title: Deep Learning Resources
date: 2015-10-09
---

* TOC
{:toc}

# ImageNet

**ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)**

- nips-page: [http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-)
- paper: [http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
- slides: [http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf](http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf)

**Going Deeper with Convolutions (GoogLeNet)**

- paper: [http://arxiv.org/abs/1409.4842](http://arxiv.org/abs/1409.4842)
- code: [https://github.com/google/inception](https://github.com/google/inception)
- blog("Building a deeper understanding of images"): [http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html](http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html)

**Very Deep Convolutional Networks for Large-Scale Image Recognition (VGGNet)**

- homepage: [http://www.robots.ox.ac.uk/~vgg/research/very_deep/](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)
- arxiv: [http://arxiv.org/abs/1409.1556](http://arxiv.org/abs/1409.1556)
- slides: [http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx](http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx)
- slides: [http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf](http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf)
- slides: [http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf](http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf)

**Rethinking the Inception Architecture for Computer Vision (Inception-v3)**

- intro: "21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network; 
3.5% top-5 error and 17.3% top-1 error With an ensemble of 4 models and multi-crop evaluation."
- arXiv: [http://arxiv.org/abs/1512.00567](http://arxiv.org/abs/1512.00567)
- github("Torch port of Inception V3"): [https://github.com/Moodstocks/inception-v3.torch](https://github.com/Moodstocks/inception-v3.torch)

**Deep Residual Learning for Image Recognition (ResNet)**

- arxiv: [http://arxiv.org/abs/1512.03385](http://arxiv.org/abs/1512.03385)
- slides: [http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf](http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf)
- gitxiv: [http://gitxiv.com/posts/LgPRdTY3cwPBiMKbm/deep-residual-learning-for-image-recognition](http://gitxiv.com/posts/LgPRdTY3cwPBiMKbm/deep-residual-learning-for-image-recognition)
- github: [https://github.com/alrojo/lasagne_residual_network](https://github.com/alrojo/lasagne_residual_network)
- github: [https://github.com/shuokay/resnet](https://github.com/shuokay/resnet)
- blog("Highway Networks and Deep Residual Networks"): [http://yanran.li/peppypapers/2016/01/10/highway-networks-and-deep-residual-networks.html](http://yanran.li/peppypapers/2016/01/10/highway-networks-and-deep-residual-networks.html)

- - -

**Network In Network**

- arxiv: [http://arxiv.org/abs/1312.4400](http://arxiv.org/abs/1312.4400)

**Striving for Simplicity: The All Convolutional Net**

- arxiv: [http://arxiv.org/abs/1412.6806](http://arxiv.org/abs/1412.6806)

**Batch-normalized Maxout Network in Network**

- arxiv: [http://arxiv.org/abs/1511.02583](http://arxiv.org/abs/1511.02583)

# Optimization Methods

**On Optimization Methods for Deep Learning**

- paper: [http://www.icml-2011.org/papers/210_icmlpaper.pdf](http://www.icml-2011.org/papers/210_icmlpaper.pdf)

**Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**

- arXiv: [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167)
- blog: [https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/](https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/)

**Flattened Convolutional Neural Networks for Feedforward Acceleration(ICLR 2015)**

- arXiv: [http://arxiv.org/abs/1412.5474](http://arxiv.org/abs/1412.5474)
- github: [https://github.com/jhjin/flattened-cnn](https://github.com/jhjin/flattened-cnn)

**Must Know Tips/Tricks in Deep Neural Networks (by Xiu-Shen Wei)**

[http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html](http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html)

**A practical theory for designing very deep convolutional neural network**

- kaggle: [https://www.kaggle.com/c/datasciencebowl/forums/t/13166/happy-lantern-festival-report-and-code/69284](https://www.kaggle.com/c/datasciencebowl/forums/t/13166/happy-lantern-festival-report-and-code/69284)
- paper: [https://kaggle2.blob.core.windows.net/forum-message-attachments/69182/2287/A%20practical%20theory%20for%20designing%20very%20deep%20convolutional%20neural%20networks.pdf?sv=2012-02-12&se=2015-12-05T15%3A40%3A02Z&sr=b&sp=r&sig=kfBQKduA1pDtu837Y9Iqyrp2VYItTV0HCgOeOok9E3E%3D](https://kaggle2.blob.core.windows.net/forum-message-attachments/69182/2287/A%20practical%20theory%20for%20designing%20very%20deep%20convolutional%20neural%20networks.pdf?sv=2012-02-12&se=2015-12-05T15%3A40%3A02Z&sr=b&sp=r&sig=kfBQKduA1pDtu837Y9Iqyrp2VYItTV0HCgOeOok9E3E%3D)
- slides: [http://vdisk.weibo.com/s/3nFsznjLKn](http://vdisk.weibo.com/s/3nFsznjLKn)

**Stochastic Optimization Techniques**

- intro: SGD/Momentum/NAG/Adagrad/RMSProp/Adadelta/Adam/ESGD/Adasecant/vSGD/Rprop
- blog: [http://colinraffel.com/wiki/stochastic_optimization_techniques](http://colinraffel.com/wiki/stochastic_optimization_techniques)

**Alec Radford's animations for optimization algorithms**

[http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html](http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html)

# Activation functions

**Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification (PReLU)**

- keywords: PReLU, Caffe "msra" weights initilization
- arXiv: [http://arxiv.org/abs/1502.01852](http://arxiv.org/abs/1502.01852)

**Empirical Evaluation of Rectified Activations in Convolutional Network (ReLU/LReLU/PReLU/RReLU)**

- arXiv: [http://arxiv.org/abs/1505.00853](http://arxiv.org/abs/1505.00853)

**Deep Learning with S-shaped Rectified Linear Activation Units (SReLU)**

- arxiv: [http://arxiv.org/abs/1512.07030](http://arxiv.org/abs/1512.07030)

# Weights Initialization

**An Explanation of Xavier Initialization**

- blog: [http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization)

**All you need is a good init**

- arxiv: [http://arxiv.org/abs/1511.06422](http://arxiv.org/abs/1511.06422)

# Loss Function

**The Loss Surfaces of Multilayer Networks**

- arxiv: [http://arxiv.org/abs/1412.0233](http://arxiv.org/abs/1412.0233)

# Tensor

**Tensorizing Neural Networks**

- paper: [http://arxiv.org/abs/1509.06569v1](http://arxiv.org/abs/1509.06569v1)
- github(TensorNet): [https://github.com/Bihaqo/TensorNet](https://github.com/Bihaqo/TensorNet)

**On the Expressive Power of Deep Learning: A Tensor Analysis**

- paper: [http://arxiv.org/abs/1509.05009](http://arxiv.org/abs/1509.05009)

**Convolutional neural networks with low-rank regularization**

- arxiv: [http://arxiv.org/abs/1511.06067](http://arxiv.org/abs/1511.06067)
- github: [https://github.com/chengtaipu/lowrankcnn](https://github.com/chengtaipu/lowrankcnn)

# Dropout

**Dropout as data augmentation**

- paper: [http://arxiv.org/abs/1506.08700](http://arxiv.org/abs/1506.08700)
- notes: [https://www.evernote.com/shard/s189/sh/ef0c3302-21a4-40d7-b8b4-1c65b8ebb1c9/24ff553fcfb70a27d61ff003df75b5a9](https://www.evernote.com/shard/s189/sh/ef0c3302-21a4-40d7-b8b4-1c65b8ebb1c9/24ff553fcfb70a27d61ff003df75b5a9)

**A Theoretically Grounded Application of Dropout in Recurrent Neural Networks**

- arxiv: [http://arxiv.org/abs/1512.05287](http://arxiv.org/abs/1512.05287)

# Deep Learning And Bayesian

**Bayesian Dark Knowledge**

- paper: [http://arxiv.org/abs/1506.04416](http://arxiv.org/abs/1506.04416)
- notes: [Notes on Bayesian Dark Knowledge](https://www.evernote.com/shard/s189/sh/92cc4cbf-285e-4038-af08-c6d9e4aee6ea/d505237e82dc81be9859bc82f3902f9f)

**Memory-based Bayesian Reasoning with Deep Learning(2015.Google DeepMind)**

- slides: [http://blog.shakirm.com/wp-content/uploads/2015/11/CSML_BayesDeep.pdf](http://blog.shakirm.com/wp-content/uploads/2015/11/CSML_BayesDeep.pdf)

# Autoencoders

**Importance Weighted Autoencoders**

- paper: [http://arxiv.org/abs/1509.00519](http://arxiv.org/abs/1509.00519)
- code: [https://github.com/yburda/iwae](https://github.com/yburda/iwae)

**Review of Auto-Encoders(by Piotr Mirowski, Microsoft Bing London, 2014)**

- slides: [https://piotrmirowski.files.wordpress.com/2014/03/piotrmirowski_2014_reviewautoencoders.pdf](https://piotrmirowski.files.wordpress.com/2014/03/piotrmirowski_2014_reviewautoencoders.pdf)
- github: [https://github.com/piotrmirowski/Tutorial_AutoEncoders/](https://github.com/piotrmirowski/Tutorial_AutoEncoders/)

**Stacked What-Where Auto-encoders**

- arxiv: [http://arxiv.org/abs/1506.02351](http://arxiv.org/abs/1506.02351)

# Semi-Supervised Learning

**Semi-Supervised Learning with Graphs (Label Propagation)**

- paper: [http://pages.cs.wisc.edu/~jerryzhu/pub/thesis.pdf](http://pages.cs.wisc.edu/~jerryzhu/pub/thesis.pdf)
- blog("标签传播算法（Label Propagation）及Python实现"): [http://blog.csdn.net/zouxy09/article/details/49105265](http://blog.csdn.net/zouxy09/article/details/49105265)

# Unsupervised Learning

**Unsupervised Learning of Spatiotemporally Coherent Metrics**

- paper: [http://arxiv.org/abs/1412.6056](http://arxiv.org/abs/1412.6056)
- code: [https://github.com/jhjin/flattened-cnn](https://github.com/jhjin/flattened-cnn)

**Unsupervised Learning on Neural Network Outputs**

- intro: "use CNN trained on the ImageNet of 1000 classes to the ImageNet of over 20000 classes"
- arXiv: [http://arxiv.org/abs/1506.00990](http://arxiv.org/abs/1506.00990)
- github: [https://github.com/yaolubrain/ULNNO](https://github.com/yaolubrain/ULNNO)

# Gradient Descent

**Fitting a model via closed-form equations vs. Gradient Descent vs Stochastic Gradient Descent vs Mini-Batch Learning. What is the difference?(Normal Equations vs. GD vs. SGD vs. MB-GD)**

[http://sebastianraschka.com/faq/docs/closed-form-vs-gd.html](http://sebastianraschka.com/faq/docs/closed-form-vs-gd.html)

**An Introduction to Gradient Descent in Python**

- blog: [http://tillbergmann.com/blog/articles/python-gradient-descent.html](http://tillbergmann.com/blog/articles/python-gradient-descent.html)

# Multi-label Learning

**CNN: Single-label to Multi-label**

- paper: [http://arxiv.org/abs/1406.5726](http://arxiv.org/abs/1406.5726)

**Deep Learning for Multi-label Classification**

- paper: [http://arxiv.org/abs/1502.05988](http://arxiv.org/abs/1502.05988)
- code: [http://meka.sourceforge.net](http://meka.sourceforge.net)

**Predicting Unseen Labels using Label Hierarchies in Large-Scale Multi-label Learning(ECML2015)**

- paper: [https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf](https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf)

**Learning with a Wasserstein Loss**

- arXiv: [http://arxiv.org/abs/1506.05439](http://arxiv.org/abs/1506.05439)
- project page: [http://cbcl.mit.edu/wasserstein/](http://cbcl.mit.edu/wasserstein/)
- code: [http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz](http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz)
- MIT news: [http://news.mit.edu/2015/more-flexible-machine-learning-1001](http://news.mit.edu/2015/more-flexible-machine-learning-1001)

# Multitask Learning

<img src="/assets/dl-materials/multitask-learning-pasted-graphic.jpg" />

[http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html](http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html)

**multi-task learning**

- discussion: [https://github.com/memect/hao/issues/93](https://github.com/memect/hao/issues/93)

# Multimodal Learning

**Multimodal Deep Learning**

- paper: [http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf](http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf)

**Multimodal Convolutional Neural Networks for Matching Image and Sentence**

![](/assets/dl_resources/multi_modal/mCNN.png)

- homepage: [http://mcnn.noahlab.com.hk/project.html](http://mcnn.noahlab.com.hk/project.html)
- paper: [http://mcnn.noahlab.com.hk/ICCV2015.pdf](http://mcnn.noahlab.com.hk/ICCV2015.pdf)
- arXiv: [http://arxiv.org/abs/1504.06063](http://arxiv.org/abs/1504.06063)

# Deep Learning Networks

**Deeply-supervised Nets (DSN)**

![](http://vcl.ucsd.edu/~sxie/images/dsn/architecture.png)

- arxiv: [http://arxiv.org/abs/1409.5185](http://arxiv.org/abs/1409.5185)
- homepage: [http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/](http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/)
- github: [https://github.com/s9xie/DSN](https://github.com/s9xie/DSN)
- notes: [http://zhangliliang.com/2014/11/02/paper-note-dsn/](http://zhangliliang.com/2014/11/02/paper-note-dsn/)

**Highway Networks**

- arxiv: [http://arxiv.org/abs/1505.00387](http://arxiv.org/abs/1505.00387)
- blog("Highway Networks with TensorFlow"): [https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa#.71fgztsb6](https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa#.71fgztsb6)

**Training Very Deep Networks (highway networks)**

- arxiv: [http://arxiv.org/abs/1507.06228](http://arxiv.org/abs/1507.06228)

**Very Deep Learning with Highway Networks**

- homepage(papers, code, FAQ): [http://people.idsia.ch/~rupesh/very_deep_learning/](http://people.idsia.ch/~rupesh/very_deep_learning/)

**Rectified Factor Networks**

- arXiv: [http://arxiv.org/abs/1502.06464](http://arxiv.org/abs/1502.06464)
- github: [https://github.com/untom/librfn](https://github.com/untom/librfn)

**Semi-Supervised Learning with Ladder Networks**

- arxiv: [http://arxiv.org/abs/1507.02672](http://arxiv.org/abs/1507.02672)
- github: [https://github.com/CuriousAI/ladder](https://github.com/CuriousAI/ladder)

**A Unified Approach for Learning the Parameters of Sum-Product Networks (SPN)**

- intro: "The Sum-Product Network (SPN) is a new type of machine learning model 
with fast exact probabilistic inference over many layers."
- arxiv: [http://arxiv.org/abs/1601.00318](http://arxiv.org/abs/1601.00318)
- homepage: [http://spn.cs.washington.edu/index.shtml](http://spn.cs.washington.edu/index.shtml)
- code: [http://spn.cs.washington.edu/code.shtml](http://spn.cs.washington.edu/code.shtml)

# Distributed System

**SparkNet: Training Deep Networks in Spark**

- arXiv: [http://arxiv.org/abs/1511.06051](http://arxiv.org/abs/1511.06051)
- github: [https://github.com/amplab/SparkNet](https://github.com/amplab/SparkNet)
- blog: [http://www.kdnuggets.com/2015/12/spark-deep-learning-training-with-sparknet.html](http://www.kdnuggets.com/2015/12/spark-deep-learning-training-with-sparknet.html)

**A Scalable Implementation of Deep Learning on Spark (Alexander Ulanov)**

- page: [http://www.slideshare.net/AlexanderUlanov1/a-scalable-implementation-of-deep-learning-on-spark-alexander-ulanov](http://www.slideshare.net/AlexanderUlanov1/a-scalable-implementation-of-deep-learning-on-spark-alexander-ulanov)
- slides: [http://pan.baidu.com/s/1jHiNW5C](http://pan.baidu.com/s/1jHiNW5C)

# Deep Learning For Driving

<img src="/assets/cnn-materials/teaser_deepdriving.jpg" width="800" />

- project: [http://deepdriving.cs.princeton.edu/](http://deepdriving.cs.princeton.edu/)
- paper: [http://deepdriving.cs.princeton.edu/paper.pdf](http://deepdriving.cs.princeton.edu/paper.pdf)
- code: [http://deepdriving.cs.princeton.edu/DeepDriving.zip](http://deepdriving.cs.princeton.edu/DeepDriving.zip)

**Recurrent Neural Networks for Driver Activity Anticipation via Sensory-Fusion Architecture**

<img src="/assets/dl-materials/bnn_fp.png" />

- paper: [http://arxiv.org/abs/1509.05016](http://arxiv.org/abs/1509.05016)
- homepage: [http://www.brain4cars.com/](http://www.brain4cars.com/)

**Eyes on the Road: How Autonomous Cars Understand What They’re Seeing**

- blog: [http://blogs.nvidia.com/blog/2016/01/05/eyes-on-the-road-how-autonomous-cars-understand-what-theyre-seeing/](http://blogs.nvidia.com/blog/2016/01/05/eyes-on-the-road-how-autonomous-cars-understand-what-theyre-seeing/)

# Deep Learning’s Accuracy

- blog: [http://deeplearning4j.org/accuracy.html](http://deeplearning4j.org/accuracy.html)	

# Deep Learning System

**DeepDetect: Open Source Deep Learning Server: Open Source + Deep Learning + API + Server**

- webiste: [http://www.deepdetect.com/](http://www.deepdetect.com/)
- github: [https://github.com/beniz/deepdetect](https://github.com/beniz/deepdetect)

**Implementation of a Practical Distributed Calculation System with Browsers and JavaScript, and Application to Distributed Deep Learning**

- arXiv: [http://arxiv.org/abs/1503.05743v1](http://arxiv.org/abs/1503.05743v1)
- github: [http://mil-tokyo.github.io/](http://mil-tokyo.github.io/)

# Paper

**Reweighted Wake-Sleep**

- paper: [http://arxiv.org/abs/1406.2751](http://arxiv.org/abs/1406.2751)
- code: [https://github.com/jbornschein/reweighted-ws](https://github.com/jbornschein/reweighted-ws)

**Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks**

- paper: [http://arxiv.org/abs/1502.05336](http://arxiv.org/abs/1502.05336)
- code: [https://github.com/HIPS/Probabilistic-Backpropagation](https://github.com/HIPS/Probabilistic-Backpropagation)

**Deeply-Supervised Nets**

- paper: [http://arxiv.org/abs/1409.5185](http://arxiv.org/abs/1409.5185)
- code: [https://github.com/mbhenaff/spectral-lib](https://github.com/mbhenaff/spectral-lib)

**An objective function for STDP(Yoshua Bengio)**

- arXiv: [http://arxiv.org/abs/1509.05936](http://arxiv.org/abs/1509.05936)

**Bitwise Neural Networks**

- paper: [http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf](http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf)
- demo: [http://minjekim.com/demo_bnn.html](http://minjekim.com/demo_bnn.html)

**Understanding and Predicting Image Memorability at a Large Scale (MIT. ICCV2015)**

- homepage: [http://memorability.csail.mit.edu/](http://memorability.csail.mit.edu/)
- paper: [https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf](https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf)
- code: [http://memorability.csail.mit.edu/download.html](http://memorability.csail.mit.edu/download.html)
- reviews: [http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/](http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/)

**A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction**

- arxiv: [http://arxiv.org/abs/1512.06293](http://arxiv.org/abs/1512.06293)

**Deep Neural Networks predict Hierarchical Spatio-temporal Cortical Dynamics of Human Visual Object Recognition**

- arxiv: [http://arxiv.org/abs/1601.02970](http://arxiv.org/abs/1601.02970)
- demo: [http://brainmodels.csail.mit.edu/dnn/drawCNN/](http://brainmodels.csail.mit.edu/dnn/drawCNN/)

# Codes

**deepnet: Implementation of some deep learning algorithms**

- github: [https://github.com/nitishsrivastava/deepnet](https://github.com/nitishsrivastava/deepnet)

**DeepNeuralClassifier(Julia): Deep neural network using rectified linear units to classify hand written digits from the MNIST dataset**

- github: [https://github.com/jostmey/DeepNeuralClassifier](https://github.com/jostmey/DeepNeuralClassifier)

**Using deep learning to break a Captcha system**

- intro: "Using Torch code to break simplecaptcha with 92% accuracy"
- blog: [https://deepmlblog.wordpress.com/2016/01/03/how-to-break-a-captcha-system/](https://deepmlblog.wordpress.com/2016/01/03/how-to-break-a-captcha-system/)
- github: [https://github.com/arunpatala/captcha](https://github.com/arunpatala/captcha)

**Breaking reddit captcha with 96% accuracy**

- blog: [https://deepmlblog.wordpress.com/2016/01/05/breaking-reddit-captcha-with-96-accuracy/](https://deepmlblog.wordpress.com/2016/01/05/breaking-reddit-captcha-with-96-accuracy/)
- github: [https://github.com/arunpatala/reddit.captcha](https://github.com/arunpatala/reddit.captcha)

# Readings and Questions

**What are the toughest neural networks and deep learning interview questions?**

[https://www.quora.com/What-are-the-toughest-neural-networks-and-deep-learning-interview-questions](https://www.quora.com/What-are-the-toughest-neural-networks-and-deep-learning-interview-questions)

**26 Things I Learned in the Deep Learning Summer School**

[http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/](http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/) <br />
[http://www.csdn.net/article/2015-09-16/2825716](http://www.csdn.net/article/2015-09-16/2825716)

**What you wanted to know about AI**

[http://fastml.com/what-you-wanted-to-know-about-ai/](http://fastml.com/what-you-wanted-to-know-about-ai/)

# Resources

**Awesome Deep Learning**

- github: [https://github.com/ChristosChristofidis/awesome-deep-learning](https://github.com/ChristosChristofidis/awesome-deep-learning)

**Deep Learning Libraries by Language**

- website: [http://www.teglor.com/b/deep-learning-libraries-language-cm569/](http://www.teglor.com/b/deep-learning-libraries-language-cm569/)

**Deep Learning Resources**

[http://yanirseroussi.com/deep-learning-resources/](http://yanirseroussi.com/deep-learning-resources/)

**Turing Machine: musings on theory & code(DEEP LEARNING REVOLUTION, summer 2015, state of the art & topnotch links)**

[https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/](https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/)

**BICV Group: Biologically Inspired Computer Vision research group**

[http://www.bicv.org/deep-learning/](http://www.bicv.org/deep-learning/)

**Learning Deep Learning**

[http://rt.dgyblog.com/ref/ref-learning-deep-learning.html](http://rt.dgyblog.com/ref/ref-learning-deep-learning.html)

# Tools

**DNNGraph - A deep neural network model generation DSL in Haskell**

- homepage: [http://ajtulloch.github.io/dnngraph/](http://ajtulloch.github.io/dnngraph/)

# Books

**Deep Learning (by Ian Goodfellow, Aaron Courville and Yoshua Bengio)**

- homepage: [http://www.deeplearningbook.org/](http://www.deeplearningbook.org/)
- website: [http://goodfeli.github.io/dlbook/](http://goodfeli.github.io/dlbook/)

# Blogs

**Neural Networks and Deep Learning**

[http://neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com)

**Deep Learning Reading List**

[http://deeplearning.net/reading-list/](http://deeplearning.net/reading-list/)

**WILDML: A BLOG ABOUT MACHINE LEARNING, DEEP LEARNING AND NLP.**

[http://www.wildml.com/](http://www.wildml.com/)

**Andrej Karpathy blog**

[http://karpathy.github.io/](http://karpathy.github.io/)

**Rodrigob's github page**

[http://rodrigob.github.io/](http://rodrigob.github.io/)

**colah's blog**

[http://colah.github.io/](http://colah.github.io/)
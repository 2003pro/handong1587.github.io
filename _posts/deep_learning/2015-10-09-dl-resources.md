---
layout: post
category: deep_learning
title: Deep Learning Resources
date: 2015-10-09
---

* TOC
{:toc}

# Tutorials

![](/assets/cnn-materials/LeNet5.png)

![](/assets/cnn-materials/conv.jpg)

[http://cs231n.github.io/assets/conv-demo/index.html](http://cs231n.github.io/assets/conv-demo/index.html)

**VGG Convolutional Neural Networks Practical**

[http://www.robots.ox.ac.uk/~vgg/practicals/cnn/index.html](http://www.robots.ox.ac.uk/~vgg/practicals/cnn/index.html)

**Hacker's guide to Neural Networks**

[http://karpathy.github.io/neuralnets/](http://karpathy.github.io/neuralnets/)

**Deep Learning Tutorials**

- website: [http://deeplearning.net/tutorial/](http://deeplearning.net/tutorial/)
- code: [https://github.com/lisa-lab/DeepLearningTutorials](https://github.com/lisa-lab/DeepLearningTutorials)

**Deep Learning in a Nutshell: Core Concepts**

[http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/](http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/)

**Deep Learning in a Nutshell: History and Training**

[http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training/](http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-history-training/)

**A Deep Learning Tutorial: From Perceptrons to Deep Networks**

[http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks](http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks)

**Deep Neural Networks(with Python code)**

- paper: [http://scholarbank.nus.edu.sg/bitstream/handle/10635/120564/DeepNeuralNetworks.pdf?sequence=1](http://scholarbank.nus.edu.sg/bitstream/handle/10635/120564/DeepNeuralNetworks.pdf?sequence=1)

**Three Classes of Deep Learning Architectures and Their Applications: A Tutorial Survey**

- paper: [http://research.microsoft.com/pubs/192937/Transactions-APSIPA.pdf](http://research.microsoft.com/pubs/192937/Transactions-APSIPA.pdf)

**UFLDL Tutorial**

[http://ufldl.stanford.edu/tutorial/](http://ufldl.stanford.edu/tutorial/)

**The Unreasonable Effectiveness of Deep Learning (LeCun)**

- slides: [http://www.ee.ucl.ac.uk/sahd2014/resources/LeCun.pdf](http://www.ee.ucl.ac.uk/sahd2014/resources/LeCun.pdf)

**Deep learning from the bottom up**

![](/assets/dl_resources/tutorials/deep_learning_from_the_bottom_up.png)

- blog: [https://www.metacademy.org/roadmaps/rgrosse/deep_learning](https://www.metacademy.org/roadmaps/rgrosse/deep_learning)

**Introduction to Deep Learning with Python (By Alec Radford. Theano)**

- youtube: [https://www.youtube.com/watch?v=S75EdAcXHKk&hd=1](https://www.youtube.com/watch?v=S75EdAcXHKk&hd=1)

**New to deep learning? Here are 4 easy lessons from Google**

- blog: [https://gigaom.com/2015/01/29/new-to-deep-learning-here-are-4-easy-lessons-from-google/](https://gigaom.com/2015/01/29/new-to-deep-learning-here-are-4-easy-lessons-from-google/)

**Deep Learning 101**

- blog: [http://markus.com/deep-learning-101/](http://markus.com/deep-learning-101/)

**Neural Networks Demystified**

- Part 1: Data and Architecture: [https://www.youtube.com/watch?v=bxe2T-V8XRs](https://www.youtube.com/watch?v=bxe2T-V8XRs)
- Part 2: Forward Propagation: [https://www.youtube.com/watch?v=UJwK6jAStmg](https://www.youtube.com/watch?v=UJwK6jAStmg)
- Part 3: Gradient Descent: [https://www.youtube.com/watch?v=5u0jaA3qAGk](https://www.youtube.com/watch?v=5u0jaA3qAGk)
- Part 4: Backpropagation: [https://www.youtube.com/watch?v=GlcnxUlrtek](https://www.youtube.com/watch?v=GlcnxUlrtek)
- Part 5: Numerical Gradient Checking: [https://www.youtube.com/watch?v=pHMzNW8Agq4](https://www.youtube.com/watch?v=pHMzNW8Agq4)
- Part 6: Training: [https://www.youtube.com/watch?v=9KM9Td6RVgQ](https://www.youtube.com/watch?v=9KM9Td6RVgQ)
- Part 7: Overfitting, Testing, and Regularization: [https://www.youtube.com/watch?v=S4ZUwgesjS8](https://www.youtube.com/watch?v=S4ZUwgesjS8)

- all-pack: [http://pan.baidu.com/s/1dDq5oNB](http://pan.baidu.com/s/1dDq5oNB)

**Deep Learning SIMPLIFIED**

- playlist: [https://www.youtube.com/playlist?list=PLjJh1vlSEYgvGod9wWiydumYl8hOXixNu](https://www.youtube.com/playlist?list=PLjJh1vlSEYgvGod9wWiydumYl8hOXixNu)

# ImageNet

**ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)**

- nips-page: [http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-)
- paper: [http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
- slides: [http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf](http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf)

**Going Deeper with Convolutions (GoogLeNet)**

- paper: [http://arxiv.org/abs/1409.4842](http://arxiv.org/abs/1409.4842)
- code: [https://github.com/google/inception](https://github.com/google/inception)

**Building a deeper understanding of images**  <br />
- blog: [http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html](http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html)

- - -

**Very Deep Convolutional Networks for Large-Scale Image Recognition (VGGNet)**

- homepage: [http://www.robots.ox.ac.uk/~vgg/research/very_deep/](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)
- arxiv: [http://arxiv.org/abs/1409.1556](http://arxiv.org/abs/1409.1556)
- slides: [http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx](http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx)
- slides: [http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf](http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf)
- slides: [http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf](http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf)

**Rethinking the Inception Architecture for Computer Vision (Inception-v3)**

- introduction: "21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network; 
3.5% top-5 error and 17.3% top-1 error With an ensemble of 4 models and multi-crop evaluation."
- arXiv: [http://arxiv.org/abs/1512.00567](http://arxiv.org/abs/1512.00567)

**Deep Residual Learning for Image Recognition (ResNet)**

- arxiv: [http://arxiv.org/abs/1512.03385](http://arxiv.org/abs/1512.03385)
- slides: [http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf](http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf)

# Optimization Methods

**On Optimization Methods for Deep Learning**

- paper: [http://www.icml-2011.org/papers/210_icmlpaper.pdf](http://www.icml-2011.org/papers/210_icmlpaper.pdf)

**Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**

- arXiv: [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167)
- blog: [https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/](https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/)

**Flattened Convolutional Neural Networks for Feedforward Acceleration(ICLR 2015)**

- arXiv: [http://arxiv.org/abs/1412.5474](http://arxiv.org/abs/1412.5474)
- github: [https://github.com/jhjin/flattened-cnn](https://github.com/jhjin/flattened-cnn)

**Must Know Tips/Tricks in Deep Neural Networks (by Xiu-Shen Wei)**

[http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html](http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html)

**A practical theory for designing very deep convolutional neural network**

- kaggle: [https://www.kaggle.com/c/datasciencebowl/forums/t/13166/happy-lantern-festival-report-and-code/69284](https://www.kaggle.com/c/datasciencebowl/forums/t/13166/happy-lantern-festival-report-and-code/69284)
- paper: [https://kaggle2.blob.core.windows.net/forum-message-attachments/69182/2287/A%20practical%20theory%20for%20designing%20very%20deep%20convolutional%20neural%20networks.pdf?sv=2012-02-12&se=2015-12-05T15%3A40%3A02Z&sr=b&sp=r&sig=kfBQKduA1pDtu837Y9Iqyrp2VYItTV0HCgOeOok9E3E%3D](https://kaggle2.blob.core.windows.net/forum-message-attachments/69182/2287/A%20practical%20theory%20for%20designing%20very%20deep%20convolutional%20neural%20networks.pdf?sv=2012-02-12&se=2015-12-05T15%3A40%3A02Z&sr=b&sp=r&sig=kfBQKduA1pDtu837Y9Iqyrp2VYItTV0HCgOeOok9E3E%3D)
- slides: [http://vdisk.weibo.com/s/3nFsznjLKn](http://vdisk.weibo.com/s/3nFsznjLKn)

**Stochastic Optimization Techniques**

- intro: SGD/Momentum/NAG/Adagrad/RMSProp/Adadelta/Adam/ESGD/Adasecant/vSGD/Rprop
- blog: [http://colinraffel.com/wiki/stochastic_optimization_techniques](http://colinraffel.com/wiki/stochastic_optimization_techniques)

# Activation functions

**Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification (PReLU)**

- keywords: PReLU, Caffe "msra" weights initilization
- arXiv: [http://arxiv.org/abs/1502.01852](http://arxiv.org/abs/1502.01852)

**Empirical Evaluation of Rectified Activations in Convolutional Network (ReLU/LReLU/PReLU/RReLU)**

- arXiv: [http://arxiv.org/abs/1505.00853](http://arxiv.org/abs/1505.00853)

**Deep Learning with S-shaped Rectified Linear Activation Units (SReLU)**

- arxiv: [http://arxiv.org/abs/1512.07030](http://arxiv.org/abs/1512.07030)

# Tensor

**Tensorizing Neural Networks**

- paper: [http://arxiv.org/abs/1509.06569v1](http://arxiv.org/abs/1509.06569v1)
- github(TensorNet): [https://github.com/Bihaqo/TensorNet](https://github.com/Bihaqo/TensorNet)

**On the Expressive Power of Deep Learning: A Tensor Analysis**

- paper: [http://arxiv.org/abs/1509.05009](http://arxiv.org/abs/1509.05009)

**Convolutional neural networks with low-rank regularization**

- arxiv: [http://arxiv.org/abs/1511.06067](http://arxiv.org/abs/1511.06067)
- github: [https://github.com/chengtaipu/lowrankcnn](https://github.com/chengtaipu/lowrankcnn)

# Dropout

**Dropout as data augmentation**

- paper: [http://arxiv.org/abs/1506.08700](http://arxiv.org/abs/1506.08700)
- notes: [https://www.evernote.com/shard/s189/sh/ef0c3302-21a4-40d7-b8b4-1c65b8ebb1c9/24ff553fcfb70a27d61ff003df75b5a9](https://www.evernote.com/shard/s189/sh/ef0c3302-21a4-40d7-b8b4-1c65b8ebb1c9/24ff553fcfb70a27d61ff003df75b5a9)

**A Theoretically Grounded Application of Dropout in Recurrent Neural Networks**

- arxiv: [http://arxiv.org/abs/1512.05287](http://arxiv.org/abs/1512.05287)

# Deep Learning And Bayesian

**Bayesian Dark Knowledge**

- paper: [http://arxiv.org/abs/1506.04416](http://arxiv.org/abs/1506.04416)
- notes: [Notes on Bayesian Dark Knowledge](https://www.evernote.com/shard/s189/sh/92cc4cbf-285e-4038-af08-c6d9e4aee6ea/d505237e82dc81be9859bc82f3902f9f)

**Memory-based Bayesian Reasoning with Deep Learning(2015.Google DeepMind)**

- slides: [http://blog.shakirm.com/wp-content/uploads/2015/11/CSML_BayesDeep.pdf](http://blog.shakirm.com/wp-content/uploads/2015/11/CSML_BayesDeep.pdf)

# Autoencoders

**Importance Weighted Autoencoders**

- paper: [http://arxiv.org/abs/1509.00519](http://arxiv.org/abs/1509.00519)
- code: [https://github.com/yburda/iwae](https://github.com/yburda/iwae)

**Review of Auto-Encoders(by Piotr Mirowski, Microsoft Bing London, 2014)**

- slides: [https://piotrmirowski.files.wordpress.com/2014/03/piotrmirowski_2014_reviewautoencoders.pdf](https://piotrmirowski.files.wordpress.com/2014/03/piotrmirowski_2014_reviewautoencoders.pdf)
- github: [https://github.com/piotrmirowski/Tutorial_AutoEncoders/](https://github.com/piotrmirowski/Tutorial_AutoEncoders/)

# Unsupervised Learning

**Unsupervised Learning of Spatiotemporally Coherent Metrics**

- paper: [http://arxiv.org/abs/1412.6056](http://arxiv.org/abs/1412.6056)
- code: [https://github.com/jhjin/flattened-cnn](https://github.com/jhjin/flattened-cnn)

**Unsupervised Learning on Neural Network Outputs**

- intro: "use CNN trained on the ImageNet of 1000 classes to the ImageNet of over 20000 classes"
- arXiv: [http://arxiv.org/abs/1506.00990](http://arxiv.org/abs/1506.00990)
- github: [https://github.com/yaolubrain/ULNNO](https://github.com/yaolubrain/ULNNO)

# Gradient Descent

**Fitting a model via closed-form equations vs. Gradient Descent vs Stochastic Gradient Descent vs Mini-Batch Learning. What is the difference?(Normal Equations vs. GD vs. SGD vs. MB-GD)**

[http://sebastianraschka.com/faq/docs/closed-form-vs-gd.html](http://sebastianraschka.com/faq/docs/closed-form-vs-gd.html)

**An Introduction to Gradient Descent in Python**

- blog: [http://tillbergmann.com/blog/articles/python-gradient-descent.html](http://tillbergmann.com/blog/articles/python-gradient-descent.html)

# Multi-label Learning

**CNN: Single-label to Multi-label**

- paper: [http://arxiv.org/abs/1406.5726](http://arxiv.org/abs/1406.5726)

**Deep Learning for Multi-label Classification**

- paper: [http://arxiv.org/abs/1502.05988](http://arxiv.org/abs/1502.05988)
- code: [http://meka.sourceforge.net](http://meka.sourceforge.net)

**Predicting Unseen Labels using Label Hierarchies in Large-Scale Multi-label Learning(ECML2015)**

- paper: [https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf](https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf)

**Learning with a Wasserstein Loss**

- arXiv: [http://arxiv.org/abs/1506.05439](http://arxiv.org/abs/1506.05439)
- project page: [http://cbcl.mit.edu/wasserstein/](http://cbcl.mit.edu/wasserstein/)
- code: [http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz](http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz)
- MIT news: [http://news.mit.edu/2015/more-flexible-machine-learning-1001](http://news.mit.edu/2015/more-flexible-machine-learning-1001)

# Multitask Learning

<img src="/assets/dl-materials/multitask-learning-pasted-graphic.jpg" />

[http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html](http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html)

**multi-task learning**

- discussion: [https://github.com/memect/hao/issues/93](https://github.com/memect/hao/issues/93)

# Multimodal Learning

**Multimodal Deep Learning**

- paper: [http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf](http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf)

**Multimodal Convolutional Neural Networks for Matching Image and Sentence**

![](/assets/dl_resources/multi_modal/mCNN.png)

- homepage: [http://mcnn.noahlab.com.hk/project.html](http://mcnn.noahlab.com.hk/project.html)
- paper: [http://mcnn.noahlab.com.hk/ICCV2015.pdf](http://mcnn.noahlab.com.hk/ICCV2015.pdf)
- arXiv: [http://arxiv.org/abs/1504.06063](http://arxiv.org/abs/1504.06063)

# Deep Learning Networks

**Highway Networks**

- arxiv: [http://arxiv.org/abs/1505.00387](http://arxiv.org/abs/1505.00387)

**Training Very Deep Networks (highway networks)**

- arxiv: [http://arxiv.org/abs/1507.06228](http://arxiv.org/abs/1507.06228)

**Very Deep Learning with Highway Networks - papers, code, FAQ**

- homepage: [http://people.idsia.ch/~rupesh/very_deep_learning/](http://people.idsia.ch/~rupesh/very_deep_learning/)

**Rectified Factor Networks**

- arXiv: [http://arxiv.org/abs/1502.06464](http://arxiv.org/abs/1502.06464)
- github: [https://github.com/untom/librfn](https://github.com/untom/librfn)

# Distributed System

**SparkNet: Training Deep Networks in Spark**

- arXiv: [http://arxiv.org/abs/1511.06051](http://arxiv.org/abs/1511.06051)
- github: [https://github.com/amplab/SparkNet](https://github.com/amplab/SparkNet)
- blog: [http://www.kdnuggets.com/2015/12/spark-deep-learning-training-with-sparknet.html](http://www.kdnuggets.com/2015/12/spark-deep-learning-training-with-sparknet.html)

**A Scalable Implementation of Deep Learning on Spark (Alexander Ulanov)**

- page: [http://www.slideshare.net/AlexanderUlanov1/a-scalable-implementation-of-deep-learning-on-spark-alexander-ulanov](http://www.slideshare.net/AlexanderUlanov1/a-scalable-implementation-of-deep-learning-on-spark-alexander-ulanov)
- slides: [http://pan.baidu.com/s/1jHiNW5C](http://pan.baidu.com/s/1jHiNW5C)

# Deep Learning For Driving

<img src="/assets/cnn-materials/teaser_deepdriving.jpg" width="800" />

- project: [http://deepdriving.cs.princeton.edu/](http://deepdriving.cs.princeton.edu/)
- paper: [http://deepdriving.cs.princeton.edu/paper.pdf](http://deepdriving.cs.princeton.edu/paper.pdf)
- code: [http://deepdriving.cs.princeton.edu/DeepDriving.zip](http://deepdriving.cs.princeton.edu/DeepDriving.zip)

**Recurrent Neural Networks for Driver Activity Anticipation via Sensory-Fusion Architecture**

<img src="/assets/dl-materials/bnn_fp.png" />

- paper: [http://arxiv.org/abs/1509.05016](http://arxiv.org/abs/1509.05016)
- homepage: [http://www.brain4cars.com/](http://www.brain4cars.com/)
	
# Deep Learning’s Accuracy

- blog: [http://deeplearning4j.org/accuracy.html](http://deeplearning4j.org/accuracy.html)	

# Deep Learning and FPGA

**Recurrent Neural Networks Hardware Implementation on FPGA**

- arXiv: [http://arxiv.org/abs/1511.05552](http://arxiv.org/abs/1511.05552)

# Deep Learning System

**DeepDetect: Open Source Deep Learning Server: Open Source + Deep Learning + API + Server**

- webiste: [http://www.deepdetect.com/](http://www.deepdetect.com/)
- github: [https://github.com/beniz/deepdetect](https://github.com/beniz/deepdetect)

**Implementation of a Practical Distributed Calculation System with Browsers and JavaScript, and Application to Distributed Deep Learning**

- arXiv: [http://arxiv.org/abs/1503.05743v1](http://arxiv.org/abs/1503.05743v1)
- github: [http://mil-tokyo.github.io/](http://mil-tokyo.github.io/)

# Deep Learning Hardware

**Building a Deep Learning (Dream) Machine**

- blog: [http://graphific.github.io/posts/building-a-deep-learning-dream-machine/](http://graphific.github.io/posts/building-a-deep-learning-dream-machine/)

**A Full Hardware Guide to Deep Learning**

- blog: [http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/](http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/)

# Paper

**Reweighted Wake-Sleep**

- paper: [http://arxiv.org/abs/1406.2751](http://arxiv.org/abs/1406.2751)
- code: [https://github.com/jbornschein/reweighted-ws](https://github.com/jbornschein/reweighted-ws)

**Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks**

- paper: [http://arxiv.org/abs/1502.05336](http://arxiv.org/abs/1502.05336)
- code: [https://github.com/HIPS/Probabilistic-Backpropagation](https://github.com/HIPS/Probabilistic-Backpropagation)

**Deeply-Supervised Nets**

- paper: [http://arxiv.org/abs/1409.5185](http://arxiv.org/abs/1409.5185)
- code: [https://github.com/mbhenaff/spectral-lib](https://github.com/mbhenaff/spectral-lib)

**An objective function for STDP(Yoshua Bengio)**

- arXiv: [http://arxiv.org/abs/1509.05936](http://arxiv.org/abs/1509.05936)

**Bitwise Neural Networks**

- paper: [http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf](http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf)
- demo: [http://minjekim.com/demo_bnn.html](http://minjekim.com/demo_bnn.html)

**Understanding and Predicting Image Memorability at a Large Scale (MIT. ICCV2015)**

- homepage: [http://memorability.csail.mit.edu/](http://memorability.csail.mit.edu/)
- paper: [https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf](https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf)
- code: [http://memorability.csail.mit.edu/download.html](http://memorability.csail.mit.edu/download.html)
- reviews: [http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/](http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/)

**A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction**

- arxiv: [http://arxiv.org/abs/1512.06293](http://arxiv.org/abs/1512.06293)

# Code

**deepnet: Implementation of some deep learning algorithms**

- github: [https://github.com/nitishsrivastava/deepnet](https://github.com/nitishsrivastava/deepnet)

**DeepNeuralClassifier(Julia): Deep neural network using rectified linear units to classify hand written digits from the MNIST dataset**

- github: [https://github.com/jostmey/DeepNeuralClassifier](https://github.com/jostmey/DeepNeuralClassifier)

# Readings and Questions

**What are the toughest neural networks and deep learning interview questions?**

[https://www.quora.com/What-are-the-toughest-neural-networks-and-deep-learning-interview-questions](https://www.quora.com/What-are-the-toughest-neural-networks-and-deep-learning-interview-questions)

**26 Things I Learned in the Deep Learning Summer School**

[http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/](http://www.marekrei.com/blog/26-things-i-learned-in-the-deep-learning-summer-school/) <br />
[http://www.csdn.net/article/2015-09-16/2825716](http://www.csdn.net/article/2015-09-16/2825716)

**What you wanted to know about AI**

[http://fastml.com/what-you-wanted-to-know-about-ai/](http://fastml.com/what-you-wanted-to-know-about-ai/)

# Resources

**Awesome Deep Learning**

- github: [https://github.com/ChristosChristofidis/awesome-deep-learning](https://github.com/ChristosChristofidis/awesome-deep-learning)

**Deep Learning Libraries by Language**

- website: [http://www.teglor.com/b/deep-learning-libraries-language-cm569/](http://www.teglor.com/b/deep-learning-libraries-language-cm569/)

**Deep Learning Resources**

[http://yanirseroussi.com/deep-learning-resources/](http://yanirseroussi.com/deep-learning-resources/)

**Turing Machine: musings on theory & code(DEEP LEARNING REVOLUTION, summer 2015, state of the art & topnotch links)**

[https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/](https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/)

**BICV Group: Biologically Inspired Computer Vision research group**

[http://www.bicv.org/deep-learning/](http://www.bicv.org/deep-learning/)

**Learning Deep Learning**

[http://rt.dgyblog.com/ref/ref-learning-deep-learning.html](http://rt.dgyblog.com/ref/ref-learning-deep-learning.html)

# Books

**Deep Learning (By Ian Goodfellow, Aaron Courville and Yoshua Bengio)**

[http://goodfeli.github.io/dlbook/](http://goodfeli.github.io/dlbook/)

# Blogs

**Neural Networks and Deep Learning**

[http://neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com)

**Deep Learning Reading List**

[http://deeplearning.net/reading-list/](http://deeplearning.net/reading-list/)

**Andrej Karpathy blog**

[http://karpathy.github.io/](http://karpathy.github.io/)

**Rodrigob's github page**

[http://rodrigob.github.io/](http://rodrigob.github.io/)

**colah's blog**

[http://colah.github.io/](http://colah.github.io/)
---
layout: post
categories: deep_learning
title: Networks Acceleration, Parameter Pruning, Model Size Reduction
---

{{ page.title }}
================

<p class="meta">09 Oct 2015 - Beijing</p>

**Neurons vs Weights Pruning in Artificial Neural Networks**

- paper: [http://journals.ru.lv/index.php/ETR/article/view/166](http://journals.ru.lv/index.php/ETR/article/view/166)

**Fast ConvNets Using Group-wise Brain Damage**

- paper: [http://arxiv.org/abs/1506.02515](http://arxiv.org/abs/1506.02515)

**Learning both Weights and Connections for Efficient Neural Networks**

- paper: [http://arxiv.org/abs/1506.02626](http://arxiv.org/abs/1506.02626)

**Data-free parameter pruning for Deep Neural Networks**

- arXiv: [http://arxiv.org/abs/1507.06149](http://arxiv.org/abs/1507.06149)

**A Deep Neural Network Compression Pipeline: Pruning, Quantization, Huffman Encoding**

- intro: "reduced the size of AlexNet by 35x from 240MB to 6.9MB, the size of VGG16 by 49x from 552MB to 11.3MB, with no loss of accuracy"
- arXiv: [http://arxiv.org/abs/1510.00149v1](http://arxiv.org/abs/1510.00149v1)

**Fast Algorithms for Convolutional Neural Networks**

- intro: "2.6x as fast as Caffe when comparing CPU implementations"
- arXiv: [http://arxiv.org/abs/1509.09308](http://arxiv.org/abs/1509.09308)
- discussion: [https://github.com/soumith/convnet-benchmarks/issues/59#issuecomment-150111895](https://github.com/soumith/convnet-benchmarks/issues/59#issuecomment-150111895)

**ZNN - A Fast and Scalable Algorithm for Training 3D Convolutional Networks on Multi-Core and Many-Core Shared Memory Machines**

- arXiv: [http://arxiv.org/abs/1510.06706](http://arxiv.org/abs/1510.06706)
- github: [https://github.com/seung-lab/znn-release](https://github.com/seung-lab/znn-release)

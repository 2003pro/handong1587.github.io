---
layout: post
category: deep_learning
title: Action Recognition
date: 2015-10-09
---

# Papers

**3d convolutional neural networks for human action recognition**

- paper: [http://www.cs.odu.edu/~sji/papers/pdf/Ji_ICML10.pdf](http://www.cs.odu.edu/~sji/papers/pdf/Ji_ICML10.pdf)

**Sequential Deep Learning for Human Action Recognition**

- paper: [http://liris.cnrs.fr/Documents/Liris-5228.pdf](http://liris.cnrs.fr/Documents/Liris-5228.pdf)

**Two-stream convolutional networks for action recognition in videos**

- arxiv: [http://arxiv.org/abs/1406.2199](http://arxiv.org/abs/1406.2199)

**Long-term Recurrent Convolutional Networks for Visual Recognition and Description (LRCN. Oral presentation at CVPR 2015)**

![](http://jeffdonahue.com/lrcn/images/lrcn_tasks.png)

- arxiv: [http://arxiv.org/abs/1411.4389](http://arxiv.org/abs/1411.4389)
- project page: [http://jeffdonahue.com/lrcn/](http://jeffdonahue.com/lrcn/)
- github: [https://github.com/BVLC/caffe/pull/2033](https://github.com/BVLC/caffe/pull/2033)

**Finding action tubes**

- intro: "built action models from shape and motion cues. 
They start from the image proposals and select the motion salient subset of them and
extract saptio-temporal features to represent the video using the CNNs."
- arxiv: [http://arxiv.org/abs/1411.6031](http://arxiv.org/abs/1411.6031)

**Hierarchical Recurrent Neural Network for Skeleton Based Action Recognition**

- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Du_Hierarchical_Recurrent_Neural_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Du_Hierarchical_Recurrent_Neural_2015_CVPR_paper.pdf)

**Action recognition with trajectory-pooled deepconvolutional descriptors**

- paper: [http://120.52.73.10/www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wang_Action_Recognition_With_2015_CVPR_paper.pdf](http://120.52.73.10/www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wang_Action_Recognition_With_2015_CVPR_paper.pdf)

**Action Recognition by Hierarchical Mid-level Action Elements**

- paper: [http://cvgl.stanford.edu/papers/tian2015.pdf](http://cvgl.stanford.edu/papers/tian2015.pdf)

**Contextual Action Recognition with R*CNN**

- paper: [http://arxiv.org/abs/1505.01197](http://arxiv.org/abs/1505.01197)
- code: [https://github.com/gkioxari/RstarCNN](https://github.com/gkioxari/RstarCNN)

**Towards Good Practices for Very Deep Two-Stream ConvNets**

- arxiv: [http://arxiv.org/abs/1507.02159](http://arxiv.org/abs/1507.02159)
- github: [https://github.com/yjxiong/caffe](https://github.com/yjxiong/caffe)

**Action Recognition using Visual Attention(LSTM/RNN)**

- arxiv: [http://arxiv.org/abs/1511.04119](http://arxiv.org/abs/1511.04119)
- project page: [http://shikharsharma.com/projects/action-recognition-attention/](http://shikharsharma.com/projects/action-recognition-attention/)
- github(Python/Theano): [https://github.com/kracwarlock/action-recognition-visual-attention](https://github.com/kracwarlock/action-recognition-visual-attention)

**Multi-velocity neural networks for gesture recognition in videos**

- arxiv: [http://arxiv.org/abs/1603.06829](http://arxiv.org/abs/1603.06829)

**ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding**

- homepage: [http://activity-net.org/](http://activity-net.org/)

**Active Learning for Online Recognition of Human Activities from Streaming Videos**

- arxiv: [http://arxiv.org/abs/1604.02855](http://arxiv.org/abs/1604.02855)

**Convolutional Two-Stream Network Fusion for Video Action Recognition**

- arxiv: [http://arxiv.org/abs/1604.06573](http://arxiv.org/abs/1604.06573)

**Deep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables**

- arxiv: [http://arxiv.org/abs/1604.08880](http://arxiv.org/abs/1604.08880)

**Unsupervised Semantic Action Discovery from Video Collections**

- arxiv: [http://arxiv.org/abs/1605.03324](http://arxiv.org/abs/1605.03324)

**Anticipating Visual Representations from Unlabeled Video**

- paper: [http://web.mit.edu/vondrick/prediction.pdf](http://web.mit.edu/vondrick/prediction.pdf)

**Deep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables**

- arxiv: [http://arxiv.org/abs/1604.08880](http://arxiv.org/abs/1604.08880)

**VideoLSTM Convolves, Attends and Flows for Action Recognition**

- arxiv: [http://arxiv.org/abs/1607.01794](http://arxiv.org/abs/1607.01794)

**Hierarchical Attention Network for Action Recognition in Videos (HAN)**

- arxiv: [http://arxiv.org/abs/1607.06416](http://arxiv.org/abs/1607.06416)

# Projects

**CUHK & ETH & SIAT Solution to ActivityNet Challenge 2016**

- intro: won the 1st place in the untrimmed video classification task of ActivityNet Challenge 2016
- github: [https://github.com/yjxiong/anet2016-cuhk](https://github.com/yjxiong/anet2016-cuhk)
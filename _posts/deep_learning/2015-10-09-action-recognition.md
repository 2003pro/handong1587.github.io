---
layout: post
category: deep_learning
title: Action / Event Recognition
date: 2015-10-09
---

# Papers

**3d convolutional neural networks for human action recognition**

- paper: [http://www.cs.odu.edu/~sji/papers/pdf/Ji_ICML10.pdf](http://www.cs.odu.edu/~sji/papers/pdf/Ji_ICML10.pdf)

**Sequential Deep Learning for Human Action Recognition**

- paper: [http://liris.cnrs.fr/Documents/Liris-5228.pdf](http://liris.cnrs.fr/Documents/Liris-5228.pdf)

**Two-stream convolutional networks for action recognition in videos**

- arxiv: [http://arxiv.org/abs/1406.2199](http://arxiv.org/abs/1406.2199)

**Finding action tubes**

- intro: "built action models from shape and motion cues. 
They start from the image proposals and select the motion salient subset of them and
extract saptio-temporal features to represent the video using the CNNs."
- arxiv: [http://arxiv.org/abs/1411.6031](http://arxiv.org/abs/1411.6031)

**Hierarchical Recurrent Neural Network for Skeleton Based Action Recognition**

- paper: [http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Du_Hierarchical_Recurrent_Neural_2015_CVPR_paper.pdf](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Du_Hierarchical_Recurrent_Neural_2015_CVPR_paper.pdf)

**Action recognition with trajectory-pooled deepconvolutional descriptors**

- paper: [http://120.52.73.10/www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wang_Action_Recognition_With_2015_CVPR_paper.pdf](http://120.52.73.10/www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wang_Action_Recognition_With_2015_CVPR_paper.pdf)

**Action Recognition by Hierarchical Mid-level Action Elements**

- paper: [http://cvgl.stanford.edu/papers/tian2015.pdf](http://cvgl.stanford.edu/papers/tian2015.pdf)

**Contextual Action Recognition with R*CNN**

- arxiv: [http://arxiv.org/abs/1505.01197](http://arxiv.org/abs/1505.01197)
- github: [https://github.com/gkioxari/RstarCNN](https://github.com/gkioxari/RstarCNN)

**Towards Good Practices for Very Deep Two-Stream ConvNets**

- arxiv: [http://arxiv.org/abs/1507.02159](http://arxiv.org/abs/1507.02159)
- github: [https://github.com/yjxiong/caffe](https://github.com/yjxiong/caffe)

**Action Recognition using Visual Attention**

- intro: LSTM / RNN
- arxiv: [http://arxiv.org/abs/1511.04119](http://arxiv.org/abs/1511.04119)
- project page: [http://shikharsharma.com/projects/action-recognition-attention/](http://shikharsharma.com/projects/action-recognition-attention/)
- github(Python/Theano): [https://github.com/kracwarlock/action-recognition-visual-attention](https://github.com/kracwarlock/action-recognition-visual-attention)

**End-to-end Learning of Action Detection from Frame Glimpses in Videos**

- intro: CVPR 2016
- project page: [http://ai.stanford.edu/~syyeung/frameglimpses.html](http://ai.stanford.edu/~syyeung/frameglimpses.html)
- arxiv: [http://arxiv.org/abs/1511.06984](http://arxiv.org/abs/1511.06984)
- paper: [http://vision.stanford.edu/pdf/yeung2016cvpr.pdf](http://vision.stanford.edu/pdf/yeung2016cvpr.pdf)

**Multi-velocity neural networks for gesture recognition in videos**

- arxiv: [http://arxiv.org/abs/1603.06829](http://arxiv.org/abs/1603.06829)

**Active Learning for Online Recognition of Human Activities from Streaming Videos**

- arxiv: [http://arxiv.org/abs/1604.02855](http://arxiv.org/abs/1604.02855)

**Convolutional Two-Stream Network Fusion for Video Action Recognition**

- arxiv: [http://arxiv.org/abs/1604.06573](http://arxiv.org/abs/1604.06573)
- github: [https://github.com/feichtenhofer/twostreamfusion](https://github.com/feichtenhofer/twostreamfusion)

**Deep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables**

- arxiv: [http://arxiv.org/abs/1604.08880](http://arxiv.org/abs/1604.08880)

**Unsupervised Semantic Action Discovery from Video Collections**

- arxiv: [http://arxiv.org/abs/1605.03324](http://arxiv.org/abs/1605.03324)

**Anticipating Visual Representations from Unlabeled Video**

- paper: [http://web.mit.edu/vondrick/prediction.pdf](http://web.mit.edu/vondrick/prediction.pdf)

**VideoLSTM Convolves, Attends and Flows for Action Recognition**

- arxiv: [http://arxiv.org/abs/1607.01794](http://arxiv.org/abs/1607.01794)

**Hierarchical Attention Network for Action Recognition in Videos (HAN)**

- arxiv: [http://arxiv.org/abs/1607.06416](http://arxiv.org/abs/1607.06416)

**Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition**

- arxiv: [http://arxiv.org/abs/1607.07043](http://arxiv.org/abs/1607.07043)

**Connectionist Temporal Modeling for Weakly Supervised Action Labeling**

- arxiv: [http://arxiv.org/abs/1607.08584](http://arxiv.org/abs/1607.08584)

## TSN

**CUHK & ETHZ & SIAT Submission to ActivityNet Challenge 2016**

- intro: won the 1st place in the untrimmed video classification task of ActivityNet Challenge 2016
- arxiv: [http://arxiv.org/abs/1608.00797](http://arxiv.org/abs/1608.00797)
- github: [https://github.com/yjxiong/anet2016-cuhk](https://github.com/yjxiong/anet2016-cuhk)

**Temporal Segment Networks: Towards Good Practices for Deep Action Recognition**

- intro: ECCV 2016. HMDB51: 69.4%, UCF101: 94.2%
- arxiv: [http://arxiv.org/abs/1608.00859](http://arxiv.org/abs/1608.00859)
- github: [https://github.com/yjxiong/temporal-segment-networks](https://github.com/yjxiong/temporal-segment-networks)

**Hierarchical Attention Network for Action Recognition in Videos**

- arxiv: [http://arxiv.org/abs/1607.06416](http://arxiv.org/abs/1607.06416)

## DeepCAMP

**DeepCAMP: Deep Convolutional Action & Attribute Mid-Level Patterns**

- intro: CVPR 2016
- arxiv: [http://arxiv.org/abs/1608.03217](http://arxiv.org/abs/1608.03217)

## Depth2Action

**Depth2Action: Exploring Embedded Depth for Large-Scale Action Recognition**

- arxiv: [http://arxiv.org/abs/1608.04339](http://arxiv.org/abs/1608.04339)

**Dynamic Image Networks for Action Recognition**

- intro: CVPR 2016
- arxiv: [http://users.cecs.anu.edu.au/~sgould/papers/cvpr16-dynamic_images.pdf](http://users.cecs.anu.edu.au/~sgould/papers/cvpr16-dynamic_images.pdf)
- github: [https://github.com/hbilen/dynamic-image-nets](https://github.com/hbilen/dynamic-image-nets)

**Human Action Recognition without Human**

- arxiv: [http://arxiv.org/abs/1608.07876](http://arxiv.org/abs/1608.07876)

**Temporal Convolutional Networks: A Unified Approach to Action Segmentation**

- arxiv: [http://arxiv.org/abs/1608.08242](http://arxiv.org/abs/1608.08242)
- ECCV 2016 workshop: [http://bravenewmotion.github.io/](http://bravenewmotion.github.io/)

**Temporal Activity Detection in Untrimmed Videos with Recurrent Neural Networks**

- intro: Bachelor Thesis Report at ETSETB TelecomBCN
- project page: [https://imatge-upc.github.io/activitynet-2016-cvprw/](https://imatge-upc.github.io/activitynet-2016-cvprw/)
- arxiv: [http://arxiv.org/abs/1608.08128](http://arxiv.org/abs/1608.08128)
- github: [https://github.com/imatge-upc/activitynet-2016-cvprw](https://github.com/imatge-upc/activitynet-2016-cvprw)

# Event Recognition

**TagBook: A Semantic Video Representation without Supervision for Event Detection**

- arxiv: [http://arxiv.org/abs/1510.02899](http://arxiv.org/abs/1510.02899)

**Better Exploiting OS-CNNs for Better Event Recognition in Images**

- arxiv: [http://arxiv.org/abs/1510.03979](http://arxiv.org/abs/1510.03979)

**Transferring Object-Scene Convolutional Neural Networks for Event Recognition in Still Images**

- arxiv: [http://arxiv.org/abs/1609.00162](http://arxiv.org/abs/1609.00162)

# Event Detection

**Devnet: A deep event network for multimedia event detection and evidence recounting**

- paper: [http://120.52.72.47/winsty.net/c3pr90ntcsf0/papers/devnet.pdf](http://120.52.72.47/winsty.net/c3pr90ntcsf0/papers/devnet.pdf)

**Detecting events and key actors in multi-person videos (CVPR 2016)**

![](https://tctechcrunch2011.files.wordpress.com/2016/06/basketball_actors.jpg)

- arxiv: [http://arxiv.org/abs/1511.02917](http://arxiv.org/abs/1511.02917)
- paper: [www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ramanathan_Detecting_Events_and_CVPR_2016_paper.pdf](www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ramanathan_Detecting_Events_and_CVPR_2016_paper.pdf)
- paper: [http://vision.stanford.edu/pdf/johnson2016cvpr.pdf](http://vision.stanford.edu/pdf/johnson2016cvpr.pdf)
- blog: [http://www.leiphone.com/news/201606/l1TKIRFLO3DUFNNu.html](http://www.leiphone.com/news/201606/l1TKIRFLO3DUFNNu.html)

# Projects

**A Torch Library for Action Recognition and Detection Using CNNs and LSTMs**

- intro: CS231n student project report
- paper: [http://cs231n.stanford.edu/reports2016/221_Report.pdf](http://cs231n.stanford.edu/reports2016/221_Report.pdf)
- github: [https://github.com/garythung/torch-lrcn](https://github.com/garythung/torch-lrcn)

**2016 ActivityNet action recognition challenge. CNN + LSTM approach. Multi-threaded loading.**

- github: [https://github.com/jrbtaylor/ActivityNet](https://github.com/jrbtaylor/ActivityNet)

# Datasets

|   Dataset         |  videos                               |  categories  |
|:-----------------:|:-------------------------------------:|:------------:|
|  UCF101           | 13320                                 | 101          |
|  HMDB51           | 7000                                  | 51           |
|  ActivityNet 200  | 10024(train) + 4926(val) + 5044(test) | 200          |
|  Sports-1M        | 100000                                | 487          |
|  Charades         | 9848                                  | 157          |

**UCF101 - Action Recognition Data Set**

![](http://crcv.ucf.edu/data/UCF101/UCF101.jpg)

- homepage: [http://crcv.ucf.edu/data/UCF101.php](http://crcv.ucf.edu/data/UCF101.php)

**HMDB51: A Large Video Database for Human Motion Recognition**

- homepage: [http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/](http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/)

**ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding**

- homepage: [http://activity-net.org/](http://activity-net.org/)
- download: [http://activity-net.org/download.html](http://activity-net.org/download.html)
- github: [https://github.com/activitynet](https://github.com/activitynet)

**Sports-1M**

- homepage: [https://github.com/gtoderici/sports-1m-dataset/blob/wiki/ProjectHome.md](https://github.com/gtoderici/sports-1m-dataset/blob/wiki/ProjectHome.md)
- github: [https://github.com/gtoderici/sports-1m-dataset/](https://github.com/gtoderici/sports-1m-dataset/)
- thumbnails: [http://cs.stanford.edu/people/karpathy/deepvideo/classes.html](http://cs.stanford.edu/people/karpathy/deepvideo/classes.html)

**Charades Dataset**

- intro: This dataset guides our research into unstructured video activity recogntion and commonsense reasoning for daily human activities.
- intro: The dataset contains 66,500 temporal annotations for 157 action classes, 
41,104 labels for 46 object classes, and 27,847 textual descriptions of the videos.
- homepage: [http://allenai.org/plato/charades/](http://allenai.org/plato/charades/)

# Challenges

**THUMOS Challenge 2014**

- homepage: [http://crcv.ucf.edu/THUMOS14/home.html](http://crcv.ucf.edu/THUMOS14/home.html)
- download: [http://crcv.ucf.edu/THUMOS14/download.html](http://crcv.ucf.edu/THUMOS14/download.html)

**THUMOS Challenge 2015**

- homepage: [http://www.thumos.info/](http://www.thumos.info/)
- download: [http://www.thumos.info/download.html](http://www.thumos.info/download.html)

**ActivityNet Challenge 2016**

![](http://activity-net.org/challenges/2016/images/anet_cover.png)

- homepage: [http://activity-net.org/challenges/2016/](http://activity-net.org/challenges/2016/)
